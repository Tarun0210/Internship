{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9b54b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tarun\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571de6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3530d61",
   "metadata": {},
   "source": [
    "# Q1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "644e3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2c30cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4be9812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product that we want to search : Guitar\n"
     ]
    }
   ],
   "source": [
    "# entering the product that we want to search\n",
    "user_input = input('Enter the product that we want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b346395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the web element for user input\n",
    "search = driver.find_element(By.XPATH,'//*[@id=\"twotabsearchtextbox\"]')\n",
    "search\n",
    "\n",
    "# sending the user input to search bar\n",
    "search.send_keys(user_input)\n",
    "\n",
    "# locating the search button using xpath\n",
    "search_btn = driver.find_element(By.XPATH,'//*[@id=\"nav-search-submit-button\"]')\n",
    "\n",
    "# clicking on search button\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc97eb",
   "metadata": {},
   "source": [
    "# Q2 : In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product vertical has less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa457a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da07c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "010eca16",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m urls \u001b[38;5;241m=\u001b[39m []          \u001b[38;5;66;03m# empty list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m):      \u001b[38;5;66;03m# for loop to scrape 3 pages\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     page_url \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/span[2]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m page_url:\n\u001b[0;32m      6\u001b[0m         urls\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# fetching URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,3):      # for loop to scrape 3 pages\n",
    "    page_url = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/span[2]')\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        next_btn = driver.find_element(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[67]/div/div/span/a[3]')\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7494bedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c5976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making empty list and fetching required data\n",
    "brand_name = []\n",
    "product_name = []\n",
    "ratings = []\n",
    "num_ratings = []\n",
    "prices = []\n",
    "exchange = []\n",
    "exp_delivery = []\n",
    "availability = []\n",
    "other_details = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #fetching brand name \n",
    "    try:\n",
    "        brand = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[23]/div/div/div/div[1]/div[1]/div/div[2]/div/div/table/tbody/tr[1]/td')\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "    \n",
    "    \n",
    "    # fetching Name of the Product\n",
    "    try:\n",
    "        product = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[1]/div/h1/span')\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append('-')\n",
    "        \n",
    "        \n",
    "\n",
    "     #fetching ratings\n",
    "    try:\n",
    "        rating = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[5]/div/span[1]/span/span[1]/a/i[1]')\n",
    "        ratings.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        ratings.append('-')\n",
    "        \n",
    " \n",
    "    #fetching  no of ratings\n",
    "    try:\n",
    "        num_rating = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[5]/div/span[3]/a/span')\n",
    "        num_ratings.append(num_rating.text)\n",
    "    except NoSuchElementException:\n",
    "        num_ratings.append('-')\n",
    "        \n",
    "\n",
    "    #fetching price of the product\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[14]/div/div/div[4]/div[1]/span[3]/span[2]/span[2]')\n",
    "        prices.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        prices.append('-')\n",
    "        \n",
    "        \n",
    "    #fetching return/exchange\n",
    "    try:\n",
    "        exch = driver.find_element(By.XPATH,'/html/body/div[2]/header/div/div[1]/div[3]/div/a[3]/span[1]')\n",
    "        exchange.append(exch.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append('-')\n",
    "        \n",
    "\n",
    "    #fetching expected delivery\n",
    "    try:\n",
    "        delivery = driver.find_element(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[4]/div/div/div/div/span/div/div/div[2]/div[5]/div/div[1]')\n",
    "        exp_delivery.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        exp_delivery.append('-')\n",
    "        \n",
    "\n",
    "    #fetching availability information\n",
    "    try:\n",
    "        avail = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[23]/div/div/h2')\n",
    "        availability.append(avail.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')\n",
    "        \n",
    "    #other details\n",
    "    try:\n",
    "        oth_det = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[23]/div/div/div/div[1]/div[1]/div/div[2]/div/div/table/tbody/tr[7]/td')\n",
    "        other_details.append(oth_det.text)\n",
    "    except NoSuchElementException:\n",
    "        other_details.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2020efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_name),\n",
    "len(product_name),\n",
    "len(ratings),\n",
    "len(num_ratings),\n",
    "len(prices),\n",
    "len(exchange),\n",
    "len(exp_delivery),\n",
    "len(availability),\n",
    "len(other_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7633e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Name of the Product</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No. of Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Other Details</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand Name, Name of the Product, Rating, No. of Ratings, Price, Return/Exchange, Expected Delivery, Availability, Other Details, Product URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the scraped data\n",
    "\n",
    "guitar = pd.DataFrame({})\n",
    "guitar['Brand Name'] = brand_name\n",
    "guitar['Name of the Product'] = product_name\n",
    "guitar['Rating'] = ratings\n",
    "guitar['No. of Ratings'] = num_ratings\n",
    "guitar['Price'] = prices\n",
    "guitar['Return/Exchange'] = exchange\n",
    "guitar['Expected Delivery'] = exp_delivery\n",
    "guitar['Availability'] = availability\n",
    "guitar['Other Details'] = other_details\n",
    "guitar['Product URL'] = urls\n",
    "guitar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bd4df",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43b8fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a68879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the webpage of mentioned url\n",
    "url = \"http://images.google.com/\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa679a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the URL you want to scrape\n",
    "url = \"https://images.google.com/\"  \n",
    "search_items = [\"Fruits\", \"Cars\", \"Machine Learning\",\"Guitar\",\"Cakes\"]\n",
    "urls = []\n",
    "\n",
    "# Create a directory for downloaded images if it doesn't exist\n",
    "download_dir = r\"E:\\google\\images\"\n",
    "\n",
    "\n",
    "# Loop through each search item\n",
    "for item in search_items:\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "\n",
    "# clicking on search button\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div/span/svg\").click()\n",
    "search_button.click()\n",
    "    \n",
    "# scrolling down the webpage to get some more images\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "    \n",
    "    # Collect image URLs    \n",
    "    imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "            if(source[0:4] == 'http'):\n",
    "                img_url.append(source)\n",
    "    for i in img_url[:100]:\n",
    "        urls.append(i)\n",
    "        \n",
    "for i in range(len(urls)):\n",
    "    if i >= 300:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i,300))\n",
    "    response = requests.get(urls[i])\n",
    "    \n",
    "    file = open(r\"E:\\google\\images\"+str(i)+\".jpg\",\"wb\")\n",
    "    \n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244e931",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "794dfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64cf6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f54e3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for web element\n",
    "search_bar = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[1]/div/div/div/div/div[1]/div/div/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "\n",
    "# sending keys to search product\n",
    "search_bar.send_keys(\"pixel 4A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f521140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating the search button using xpath\n",
    "search_btn = driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "# clicking on search button\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a3c3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching 1st page of URLs of smartphone\n",
    "page1_url = []\n",
    "urls = driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[26]/div/div/nav/a[1]')\n",
    "for url in urls:\n",
    "    href = url.get_attribute('href')\n",
    "    if href:  # Ensure href is not None or empty\n",
    "        page1_url.append(href)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33919a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page1_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22946d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Smartphones = ({})\n",
    "Smartphones['Brand'] = []\n",
    "Smartphones['Phone name'] = []\n",
    "Smartphones['Colour'] = []\n",
    "Smartphones['RAM'] = []\n",
    "Smartphones['Storage(ROM)'] = []\n",
    "Smartphones['Primary Camera'] = []\n",
    "Smartphones['Secondary Camera'] = []\n",
    "Smartphones['Display Size'] = []\n",
    "Smartphones['Display Resolution'] = []\n",
    "Smartphones['Processor'] = []\n",
    "Smartphones['Processor Cores'] = []\n",
    "Smartphones['Battery Capacity'] = []\n",
    "Smartphones['Price'] = []\n",
    "Smartphones['URL'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5dbd189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL = https://www.flipkart.com/search?q=pixel+4A&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1\n",
      "Exception occured while moving to next page\n"
     ]
    }
   ],
   "source": [
    "# scraping data from each url of page 1\n",
    "for url in page1_url:\n",
    "    driver.get(url)\n",
    "    print(\"Scraping URL =\",url)\n",
    "    Smartphones['URL'].append(url)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clicking on read more button to get more information\n",
    "    try:\n",
    "        read_more = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/button')\n",
    "        read_more.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception occured while moving to next page\")\n",
    "    \n",
    "    #scraping brand name of smartphone\n",
    "    try:\n",
    "        brand_tags = driver.find_element(By.XPATH,' /html/body/div[1]/div/div[3]/div[1]/div[2]/div[1]/div[1]/div/div[4]/a')\n",
    "        Smartphones['Brand'].append(brand_tags.text.split()[0])\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Brand'].append('-')\n",
    "    \n",
    "    \n",
    "    # scraping name of smartphones      \n",
    "    try:\n",
    "        name_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span')\n",
    "        Smartphones['Phone name'].append(name_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Phone name'].append('-')\n",
    "        \n",
    "    #scraping colour of smartphone\n",
    "    try:\n",
    "        color_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[2]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        Smartphones['Colour'].append(color_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Colour'].append('-')\n",
    "        \n",
    "    # scraping RAM data of smartphone\n",
    "    try:\n",
    "        ram_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[4]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Smartphones['RAM'].append(ram_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['RAM'].append('-')\n",
    "        \n",
    "    #scraping ROM data of smartphones\n",
    "    try:\n",
    "        rom = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[4]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        Smartphones['Storage(ROM)'].append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Storage(ROM)'].append('-')\n",
    "        \n",
    "    # scraping  Primary camera data of smartphone\n",
    "    try:\n",
    "        pri =driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Smartphones['Primary Camera'].append(pri.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Primary Camera'].append('-')\n",
    "        \n",
    "    # scraping secondary camera data of smartphone\n",
    "    try:\n",
    "        sec = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[5]/td[2]/ul/li')\n",
    "        if sec != 'Secondary Camera' :\n",
    "            if driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[5]/td[2]/ul/li').text == \"Secondary Camera\":\n",
    "                sec_cam =driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[5]/td[2]/ul/li')\n",
    "            else :\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            sec_cam = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[5]/td[2]/ul/li')\n",
    "        Smartphones['Secondary Camera'].append(sec_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Secondary Camera'].append('-')\n",
    "        \n",
    "    \n",
    "    #scraping display size data of smartphone\n",
    "    try:\n",
    "        disp = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[1]/div/div[2]/ul/li[2]')\n",
    "        if disp.text != 'Display Features' : raise NoSuchElementException\n",
    "        disp_size = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[1]/div/div[2]/ul/li[2]')\n",
    "        Smartphones['Display Size'].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Display Size'].append('-')\n",
    "        \n",
    "    \n",
    "    #scraping display resolution of smartphone\n",
    "    try:\n",
    "        disp = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[2]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        if disp.text != 'Display Features' : raise NoSuchElementException\n",
    "        disp_reso = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[2]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Smartphones['Display Resolution'].append(disp_reso.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Display Resolution'].append('-')\n",
    "        \n",
    "        \n",
    "    #scraping processor of smartphone\n",
    "    try:\n",
    "        pro = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[1]/div/div[2]/ul/li[5]')\n",
    "        if pro.text != 'Processor Type' : raise NoSuchElementException\n",
    "        processor = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[1]/div/div[2]/ul/li[5]')\n",
    "        Smartphones['Processor'].append(processor.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Processor'].append('-')\n",
    "    \n",
    "        \n",
    "       \n",
    "    # scraping processor core of smartphone\n",
    "    try:\n",
    "        core = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[3]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        if core.text != 'Processor Core' :\n",
    "            core = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[3]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "            if core.text != 'Processor Core' :\n",
    "                raise NoSuchElementException\n",
    "            else :\n",
    "                cores = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[3]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        else :\n",
    "            cores = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[3]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        Smartphones['Processor Cores'].append(disp_reso.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Processor Cores'].append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "    # scraping the battery capacity of smartphone\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li').text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "            elif driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][8]/div\").text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "            if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_capa = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[8]/table/tbody/tr/td[2]/ul/li')\n",
    "        Smartphones['Battery Capacity'].append(bat_capa.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Battery Capacity'].append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping price of smartphone\n",
    "    try:\n",
    "        price_tags = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[1]/div/div')\n",
    "        Smartphones['Price'].append(price_tags.text)\n",
    "    except NoSuchElementException:\n",
    "          Smartphones['Price'].append('-')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e6f71572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "# checking lengths of all scraped data\n",
    "\n",
    "print(len(Smartphones['Brand']),len(Smartphones['Phone name']), len(Smartphones['Colour']),len(Smartphones['RAM']),len(Smartphones['Storage(ROM)']),len(Smartphones['Primary Camera']),len(Smartphones['Secondary Camera']), len(Smartphones['Display Size']), len(Smartphones['Display Resolution']), len(Smartphones['Processor']), len(Smartphones['Processor Cores']), len(Smartphones['Battery Capacity']), len(Smartphones['Price']), len(Smartphones['URL'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e239c5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Phone name</th>\n",
       "      <th>Colour</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Storage(ROM)</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Secondary Camera</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Display Resolution</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Processor Cores</th>\n",
       "      <th>Battery Capacity</th>\n",
       "      <th>Price</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.flipkart.com/search?q=pixel+4A&amp;otr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Phone name Colour RAM Storage(ROM) Primary Camera Secondary Camera  \\\n",
       "0     -          -      -   -            -              -                -   \n",
       "\n",
       "  Display Size Display Resolution Processor Processor Cores Battery Capacity  \\\n",
       "0            -                  -         -               -                -   \n",
       "\n",
       "  Price                                                URL  \n",
       "0     -  https://www.flipkart.com/search?q=pixel+4A&otr...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# framing the DataFrame\n",
    "\n",
    "df = pd.DataFrame.from_dict(Smartphones)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f9666878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data in csv\n",
    "df.to_csv(\"smartphones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a463865",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96df87f",
   "metadata": {},
   "source": [
    "# Q5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "455b07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ffbd160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting mentioned url and opening google maps web page\n",
    "url = 'https://www.google.co.in/maps'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd81e00",
   "metadata": {},
   "outputs": [],
   "source": [
    " # entering the city name in search bar\n",
    "City = input('Enter City name that has to be searched : ')\n",
    "search_bar = driver.find_element_by_id('searchboxinput')\n",
    "search_bar.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#sending keys to find cities\n",
    "search_bar.send_keys(City)\n",
    "\n",
    "#checking for webelement and clicking on search button\n",
    "search_btn = driver.find_element_by_id(\"searchbox-searchbutton\")\n",
    "search_btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    url_str = driver.current_url\n",
    "    print(\"URL Extracted: \", url_str)\n",
    "    latitude_longitude = re.findall(r'@(.*)data',url_str)\n",
    "    if len(latitude_longitude):\n",
    "        lat_lng_list = latitude_longitude[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            latitude = lat_lng_list[0]\n",
    "            longitude = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(latitude, longitude))\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26957e",
   "metadata": {},
   "source": [
    "# Q6. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4479ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb5f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b06427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the url digit.in\n",
    "url = \"https://www.digit.in/\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b190b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for best Laptop\n",
    "best_gaming_laptops = driver.find_element(By.XPATH,'//*[@id=\"mobile-menu-icons\"]/button').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "697d6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Laptop_Name = []\n",
    "Operating_sys = []\n",
    "Display = []\n",
    "Processor = []\n",
    "Memory = []\n",
    "Weight = []\n",
    "Dimensions = []\n",
    "Graph_proc = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac252b10",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#scraping the data of laptop names\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m laptop_name \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[1]/h4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m laptop_name:\n\u001b[0;32m      4\u001b[0m     Laptop_Name\u001b[38;5;241m.\u001b[39mappend(name\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n"
     ]
    }
   ],
   "source": [
    "#scraping the data of laptop names\n",
    "laptop_name = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[1]/h4')\n",
    "for name in laptop_name:\n",
    "    Laptop_Name.append(name.text)\n",
    "    \n",
    "#scraping the data of operating system\n",
    "try:\n",
    "    op_sys = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[2]/td/table/tbody/tr[1]/th')\n",
    "    for os in op_sys:\n",
    "        Operating_sys.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#scraping data of display of the Laptop\n",
    "try:\n",
    "    display = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[3]/th')\n",
    "    for disp in display:\n",
    "        Display.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping data of processor\n",
    "try:\n",
    "    processor = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[9]/th')\n",
    "    for pro in processor:\n",
    "        Processor.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping the data of memory\n",
    "try:\n",
    "    memory = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[5]/th')\n",
    "    for memo in memory:\n",
    "        Memory.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping data of weight\n",
    "try:\n",
    "    weight = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[8]/td/table/tbody/tr[2]/th')\n",
    "    for wgt in weight:\n",
    "        Weight.append(wgt.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping data of dimensions\n",
    "try:\n",
    "    dimension = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[8]/td/table/tbody/tr[1]/th')\n",
    "    for dim in dimension:\n",
    "        Dimensions.append(dim.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping data of graph processor\n",
    "try:\n",
    "    graph = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[4]/div[2]/div[2]/table/tbody/tr[10]/td/table/tbody/tr[4]/th')\n",
    "    for gra in graph:\n",
    "        Graph_proc.append(gra.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "# scraping the data of price\n",
    "try:\n",
    "    price = driver.find_elements(By.XPATH,'/html/body/div[2]/div[3]/div/div/div/div/div[2]/div[3]/div/div[3]/div[1]/p/span/bdi')\n",
    "    for pri in price:\n",
    "        Price.append(pri.text.replace('₹ ','Rs'))\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1059b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Laptop_Name),\n",
    "len(Operating_sys),\n",
    "len(Display),\n",
    "len(Processor),\n",
    "len(Memory),\n",
    "len(Weight),\n",
    "len(Dimensions),\n",
    "len(Graph_proc),\n",
    "len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cb8bc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Operating System</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Graphical Processor</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Laptop Name, Operating System, Display, Processor, Memory, Weight, Dimensions, Graphical Processor, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for scraped data\n",
    "Gaming_Laptop=pd.DataFrame({})\n",
    "Gaming_Laptop['Laptop Name'] = Laptop_Name\n",
    "Gaming_Laptop['Operating System'] =Operating_sys\n",
    "Gaming_Laptop['Display'] = Display\n",
    "Gaming_Laptop['Processor'] = Processor\n",
    "Gaming_Laptop['Memory'] = Memory\n",
    "Gaming_Laptop['Weight'] = Weight\n",
    "Gaming_Laptop['Dimensions'] = Dimensions\n",
    "Gaming_Laptop['Graphical Processor'] = Graph_proc\n",
    "Gaming_Laptop['Price'] = Price\n",
    "Gaming_Laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ad3c6",
   "metadata": {},
   "source": [
    "# Q7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f457243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a4a256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the specified url\n",
    "url = \"https://www.forbes.com/?sh=41bd46d2254c\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c1efb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get option button from the page\n",
    "opt_btn = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[1]/header/div[1]/div/div')\n",
    "time.sleep(3)\n",
    "\n",
    "#select billionaires from options\n",
    "blns = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[1]/header/div[1]/div/div[2]/ul/li[2]')\n",
    "blns.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#select world billionaire\n",
    "bln_list = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[1]/header/div[1]/div/div[2]/ul/li[2]/div[2]/div[3]/ul/li[1]/a')\n",
    "bln_list.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b7b7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping required data from the web page\n",
    "# creating empty lists\n",
    "Rank = []\n",
    "Person_Name = []\n",
    "Net_worth = []\n",
    "Age = []\n",
    "Citizenship = []\n",
    "Source = []\n",
    "Industry = []\n",
    "\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # scraping the data of rank of the billionaires\n",
    "    rank_tag = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/div[2]/div/div/div[3]/div[2]/div[2]/div/div[1]/div[2]/div[1]/div')\n",
    "    for rank in rank_tag:\n",
    "        Rank.append(rank.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    " \n",
    "    # scraping the data  of names of the billionaires\n",
    "    name_tag = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/div[2]/div/div/div[3]/div[2]/div[2]/div/div[1]/div[2]/div[2]/div')\n",
    "    for name in name_tag:\n",
    "        Person_Name.append(name.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping the data of age of the billionaires\n",
    "    age_tag = driver.find_elements(By.XPATH,'/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/dl/dl[1]/dt')\n",
    "    for age in age_tag:\n",
    "        Age.append(age.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping the data of citizenship of the billionaires\n",
    "    cit_tag = driver.find_elements(By.XPATH,'/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/dl/dl[4]/dt')\n",
    "    for cit in cit_tag:    \n",
    "        Citizenship.append(cit.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping the data of source of income of the billionaires\n",
    "    sour_tag = driver.find_elements(By.XPATH,'/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/dl/dl[2]/dt')\n",
    "    for sour in sour_tag:\n",
    "        Source.append(sour.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping data of industry of the billionaires\n",
    "    ind_tag = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/div[2]/div/div/div[3]/div[2]/div[2]/div/div[1]/div[2]/div[4]/div/div')\n",
    "    for ind in ind_tag:\n",
    "        Industry.append(ind.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # scraping data of net_worth of billionaires\n",
    "    net_tag = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/div[2]/div/div/div[3]/div[2]/div[2]/div/div[1]/div[2]/div[3]/div/div')\n",
    "    for net in net_tag:\n",
    "        Net_worth.append(net.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # clicking on next button\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[2]/div/div/div[3]/div[2]/div[2]/div/div[2]/div[27]/div[7]/div[1]/nav/div/button[7]')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "191bfd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),\n",
    "len(Person_Name),\n",
    "len(Net_worth),\n",
    "len(Age),\n",
    "len(Citizenship),\n",
    "len(Source),\n",
    "len(Industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# framing Data\n",
    "Billionaires = pd.DataFrame({})\n",
    "Billionaires['Rank'] = Rank\n",
    "Billionaires['Name'] = Person_Name\n",
    "Billionaires['Net Worth'] = Net_worth\n",
    "Billionaires['Age'] = Age\n",
    "Billionaires['Citizenship'] = Citizenship\n",
    "Billionaires['Source'] = Source\n",
    "Billionaires['Industry'] = Industry\n",
    "Billionaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925bfe4",
   "metadata": {},
   "source": [
    "# Q8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55769485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "926c60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the youtube.com\n",
    "url = \"https://www.youtube.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a945bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for search bar\n",
    "search_bar = driver.find_element(By.XPATH,'/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/form/div[1]/div[1]/input')\n",
    "search_bar.send_keys(\"GOT\")      # entering video name\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf819ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_btn = driver.find_element(By.XPATH,'/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/button')\n",
    "search_btn.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54c0e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on first video\n",
    "video = driver.find_element(By.XPATH,'/html/body/ytd-app/div[1]/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[1]/div[1]/div/div[1]/div/h3/a/yt-formatted-string')\n",
    "video.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f89d7a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1000 times we scroll down by 10000 in order to generate more comments\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollBy(0,10000)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:414\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    411\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    412\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(command, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m\"\u001b[39m: script, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: converted_args})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# 1000 times we scroll down by 10000 in order to generate more comments\n",
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c175936",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m No_of_Likes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# scrape comments\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m cm \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[2]/ytd-comment-view-model/div[3]/div[2]/ytd-expander/div\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cm:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=129.0.6668.60)\nStacktrace:\n\tGetHandleVerifier [0x00007FF774F1B125+29573]\n\t(No symbol) [0x00007FF774E8FF50]\n\t(No symbol) [0x00007FF774D4B6EA]\n\t(No symbol) [0x00007FF774D32BAC]\n\t(No symbol) [0x00007FF774D32A70]\n\t(No symbol) [0x00007FF774D4E0B1]\n\t(No symbol) [0x00007FF774DE7FE9]\n\t(No symbol) [0x00007FF774DC70A3]\n\t(No symbol) [0x00007FF774D912DF]\n\t(No symbol) [0x00007FF774D92441]\n\tGetHandleVerifier [0x00007FF77524C76D+3377613]\n\tGetHandleVerifier [0x00007FF775297B67+3685831]\n\tGetHandleVerifier [0x00007FF77528CF8B+3641835]\n\tGetHandleVerifier [0x00007FF774FDB2A6+816390]\n\t(No symbol) [0x00007FF774E9B25F]\n\t(No symbol) [0x00007FF774E97084]\n\t(No symbol) [0x00007FF774E97220]\n\t(No symbol) [0x00007FF774E8607F]\n\tBaseThreadInitThunk [0x00007FF852637374+20]\n\tRtlUserThreadStart [0x00007FF852C5CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# creating empty lists\n",
    "comments = []\n",
    "comment_time = []\n",
    "Time = []\n",
    "Likes = []\n",
    "No_of_Likes = []\n",
    "\n",
    "# scrape comments\n",
    "cm = driver.find_elements(By.XPATH,'/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[2]/ytd-comment-view-model/div[3]/div[2]/ytd-expander/div')\n",
    "for i in cm:\n",
    "    if i.text is None:\n",
    "        comments.append(\"--\")\n",
    "    else:\n",
    "        comments.append(i.text)\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# scrape time when comment was posted\n",
    "tm = driver.find_elements(By.XPATH,'/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[2]/ytd-comment-view-model/div[3]/div[2]/div/div[2]/span[3]/a')\n",
    "for i in tm:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "for i in range(0,len(Time),2):\n",
    "    comment_time.append(Time[i])\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# scrape the comment likes\n",
    "like = driver.find_elements(By.XPATH,'/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[1]/ytd-comment-view-model/div[3]/div[2]/ytd-comment-engagement-bar/div[1]/span')\n",
    "for i in like:\n",
    "    Likes.append(i.text)\n",
    "    \n",
    "for i in range(1,len(Likes),2):\n",
    "    No_of_Likes.append(Likes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1179e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(comments),len(comment_time),len(No_of_Likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53c46b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment Time</th>\n",
       "      <th>Comment Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Comment, Comment Time, Comment Upvotes]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "\n",
    "Youtube = pd.DataFrame({})\n",
    "Youtube['Comment'] = comments[:500]\n",
    "Youtube['Comment Time'] = comment_time[:500]\n",
    "Youtube['Comment Upvotes'] = No_of_Likes[:500]\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93762a9e",
   "metadata": {},
   "source": [
    "# Q9 Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c09ce1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e625d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the web page of mentioned url\n",
    "url = \"https://www.hostelworld.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb6a18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating the location search bar\n",
    "search_bar = driver.find_element(By.XPATH,'/html/body/div[3]/div/div[3]/main/header/div/div[2]/div[1]/div[1]/div/div[1]/div/div/div[2]/label/input')\n",
    "\n",
    "# entering London in search bar\n",
    "search_bar.send_keys(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8af2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select London\n",
    "London = driver.find_element(By.XPATH,'/html/body/div[3]/div/div[3]/main/header/div/div[2]/div[1]/div[1]/div/div[1]/div[1]/div/div[2]/label/input')\n",
    "#clicking on button\n",
    "London.click()\n",
    "\n",
    "# do click on Let's Go button\n",
    "search_btn = driver.find_element(By.XPATH,'/html/body/div[3]/div/div[3]/main/header/div/div[2]/div[1]/div[1]/div/div[1]/div[2]/div/ul/li[2]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55f4e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list & find required data\n",
    "hostel_name = []\n",
    "distance = []\n",
    "pvt_prices = []\n",
    "dorms_price = []\n",
    "rating = []\n",
    "reviews = []\n",
    "over_all = []\n",
    "facilities = []\n",
    "description = []\n",
    "url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52c57dff",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=128.0.6613.138)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B6CD9412+29090]\n\t(No symbol) [0x00007FF6B6C4E239]\n\t(No symbol) [0x00007FF6B6B0B1DA]\n\t(No symbol) [0x00007FF6B6AF28FC]\n\t(No symbol) [0x00007FF6B6AF27C0]\n\t(No symbol) [0x00007FF6B6B0DAC1]\n\t(No symbol) [0x00007FF6B6BA5ED9]\n\t(No symbol) [0x00007FF6B6B86493]\n\t(No symbol) [0x00007FF6B6B509D1]\n\t(No symbol) [0x00007FF6B6B51B31]\n\tGetHandleVerifier [0x00007FF6B6FF871D+3302573]\n\tGetHandleVerifier [0x00007FF6B7044243+3612627]\n\tGetHandleVerifier [0x00007FF6B703A417+3572135]\n\tGetHandleVerifier [0x00007FF6B6D95EB6+801862]\n\t(No symbol) [0x00007FF6B6C5945F]\n\t(No symbol) [0x00007FF6B6C54FB4]\n\t(No symbol) [0x00007FF6B6C55140]\n\t(No symbol) [0x00007FF6B6C4461F]\n\tBaseThreadInitThunk [0x00007FF8FCE07374+20]\n\tRtlUserThreadStart [0x00007FF8FD51CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# scraping the required informations\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__layout\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      3\u001b[0m     i\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m      4\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=128.0.6613.138)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B6CD9412+29090]\n\t(No symbol) [0x00007FF6B6C4E239]\n\t(No symbol) [0x00007FF6B6B0B1DA]\n\t(No symbol) [0x00007FF6B6AF28FC]\n\t(No symbol) [0x00007FF6B6AF27C0]\n\t(No symbol) [0x00007FF6B6B0DAC1]\n\t(No symbol) [0x00007FF6B6BA5ED9]\n\t(No symbol) [0x00007FF6B6B86493]\n\t(No symbol) [0x00007FF6B6B509D1]\n\t(No symbol) [0x00007FF6B6B51B31]\n\tGetHandleVerifier [0x00007FF6B6FF871D+3302573]\n\tGetHandleVerifier [0x00007FF6B7044243+3612627]\n\tGetHandleVerifier [0x00007FF6B703A417+3572135]\n\tGetHandleVerifier [0x00007FF6B6D95EB6+801862]\n\t(No symbol) [0x00007FF6B6C5945F]\n\t(No symbol) [0x00007FF6B6C54FB4]\n\t(No symbol) [0x00007FF6B6C55140]\n\t(No symbol) [0x00007FF6B6C4461F]\n\tBaseThreadInitThunk [0x00007FF8FCE07374+20]\n\tRtlUserThreadStart [0x00007FF8FD51CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# scraping the required informations\n",
    "for i in driver.find_elements(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]'):\n",
    "    i.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping hostel name\n",
    "    try:\n",
    "        name = driver.find_elements(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]/div[1]/div[2]/span')\n",
    "        for i in name:\n",
    "            hostel_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        hostel_name.append('-')\n",
    "        \n",
    "        \n",
    "    # scraping distance from city centre\n",
    "    try:\n",
    "        dist = driver.find_elements(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]/div[2]/span[2]')\n",
    "        for i in name:\n",
    "            distance.append(i.text.replace('Hostel - ',''))\n",
    "    except NoSuchElementException:\n",
    "        distance.append('-')\n",
    "        \n",
    "   \n",
    "  \n",
    "     # scraping privates from price\n",
    "        try:\n",
    "            pvt_price = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]/div[4]/div/div[1]/div[3]/strong')\n",
    "            pvt_prices.append(pvt_price.text)\n",
    "        except NoSuchElementException:\n",
    "            pvt_prices.append('-')\n",
    "   \n",
    "\n",
    "         \n",
    "    # scraping dorms from price\n",
    "        try:\n",
    "            dorms = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[2]/div[1]/div/div[6]/div[1]/a/a/div[2]/div[4]/div/div[2]/div[3]/strong')\n",
    "            dorms_price.append(dorms.text)\n",
    "        except NoSuchElementException:\n",
    "            dorms_price.append('-')\n",
    "            \n",
    "            \n",
    "    # scraping facilities\n",
    "    try:\n",
    "        fac1 = driver.find_elements(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[5]/div/div/div[2]/div/div[2]/div[2]/div/div[1]/div/div[2]/span')\n",
    "        fac2 = driver.find_elements(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[4]/div[1]/div[5]/div/div[3]/div/div/div[4]/span')\n",
    "        for i in fac1:\n",
    "            for j in fac2:\n",
    "                facilities.append(i.text +', '+ j.text)\n",
    "    except NoSuchElementException:\n",
    "        facilities.append('-')\n",
    "     \n",
    "            \n",
    "    #fetching url of each hostel\n",
    "    p_url = driver.find_elements(By.XPATH,'')\n",
    "    for i in p_url:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "        \n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # scraping ratings\n",
    "    try:\n",
    "        rat = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[4]/div[1]/div[6]/div/div/div[1]/div/div[1]/div[1]/div[1]/span[1]')\n",
    "        rating.append(rat.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')\n",
    "        \n",
    "        \n",
    "    # scraping total review\n",
    "    try:\n",
    "        rws = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[5]/div/div[2]/div[2]/div[3]/div[11]')\n",
    "        reviews.append(rws.text.replace('Total Reviews',''))\n",
    "    except NoSuchElementException:\n",
    "        reviews.append('-')\n",
    "        \n",
    "        \n",
    "    # fetching over all review\n",
    "    try:\n",
    "        overall = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[4]/div[1]/div[6]/div/div/div[2]')\n",
    "        over_all.append(overall.text)\n",
    "    except NoSuchElementException:\n",
    "        over_all.append('-')\n",
    "        \n",
    "        \n",
    "    # fetching property description\n",
    "    try:\n",
    "        disc = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[4]/div[1]/div[1]/div/p')\n",
    "        description.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "        over_all.append('-')\n",
    "    \n",
    "    # do click on show more button for description\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[2]/div[4]/div[1]/div[1]/div/button').click()\n",
    "        time.sleep(4)\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cb5cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(hostel_name),\n",
    "len(distance),\n",
    "len(pvt_prices),\n",
    "len(dorms_price),\n",
    "len(rating),\n",
    "len(reviews),\n",
    "len(over_all),\n",
    "len(facilities),\n",
    "len(description),\n",
    "len(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1246df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostel Name</th>\n",
       "      <th>Distance from City Centre</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Total Reviews</th>\n",
       "      <th>Overall Reviews</th>\n",
       "      <th>Privates from Price</th>\n",
       "      <th>Dorms from Price</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Hostel Name, Distance from City Centre, Ratings, Total Reviews, Overall Reviews, Privates from Price, Dorms from Price, Facilities, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame\n",
    "Hostel = pd.DataFrame({})\n",
    "Hostel['Hostel Name'] = hostel_name\n",
    "Hostel['Distance from City Centre'] = distance\n",
    "Hostel['Ratings'] = rating\n",
    "Hostel['Total Reviews'] = reviews\n",
    "Hostel['Overall Reviews'] = over_all\n",
    "Hostel['Privates from Price'] = pvt_prices\n",
    "Hostel['Dorms from Price'] = dorms_price\n",
    "Hostel['Facilities'] = facilities[:74]\n",
    "Hostel['Description'] = description\n",
    "Hostel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ddea76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

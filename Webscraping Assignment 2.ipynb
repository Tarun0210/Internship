{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4eb652",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Scientist” Job position in “Delhi/NCR” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "dbb7dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tarun\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "499f828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b00bf01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d17f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Naukri.com website\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c28cf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "\n",
    "designation= driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2dae110f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_field_loc=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "search_field_loc.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c5a55668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search bar button\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac360287",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "97acc1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//*[@id=\"listContainer\"]/div[2]/div/div[*]/div/div[1]/a')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//*[@id=\"listContainer\"]/div[2]/div/div[*]/div/div[3]/div/span[3]/span/span')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//*[@id=\"listContainer\"]/div[2]/div/div[*]/div/div[2]/span/a[1]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//*[@id=\"listContainer\"]/div[2]/div/div[*]/div/div[3]/div/span[1]/span/span')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "034a51c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(experience_required),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a8bd96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen AI Data Scientist - Pan India</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hyderabad, Gurugram, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IIFL Finance</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nityo Infotech</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vision Language Data Scientist</td>\n",
       "      <td>Neal Analytics</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurugram, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist with GCP Cloud</td>\n",
       "      <td>Foreign MNC</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Delhi / NCR, Hyderabad, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Maruti Suzuki</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>One of the global analytics and digital soluti...</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Hybrid - Noida, Gurugram, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jobpoint</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hybrid - Gurugram, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Rarr Technologies</td>\n",
       "      <td>10-16 Yrs</td>\n",
       "      <td>Faridabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Rarr Technologies</td>\n",
       "      <td>6-12 Yrs</td>\n",
       "      <td>Faridabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title  \\\n",
       "0  Gen AI Data Scientist - Pan India   \n",
       "1                     Data Scientist   \n",
       "2                     Data Scientist   \n",
       "3     Vision Language Data Scientist   \n",
       "4      Data Scientist with GCP Cloud   \n",
       "5                     Data Scientist   \n",
       "6                     Data Scientist   \n",
       "7                     Data Scientist   \n",
       "8                     Data Scientist   \n",
       "9                     Data Scientist   \n",
       "\n",
       "                                        company_name experience_required  \\\n",
       "0                                            Genpact            6-11 Yrs   \n",
       "1                                       IIFL Finance             3-6 Yrs   \n",
       "2                                     Nityo Infotech             3-7 Yrs   \n",
       "3                                     Neal Analytics             1-6 Yrs   \n",
       "4                                        Foreign MNC            6-11 Yrs   \n",
       "5                                      Maruti Suzuki             4-7 Yrs   \n",
       "6  One of the global analytics and digital soluti...             3-5 Yrs   \n",
       "7                                           Jobpoint             3-8 Yrs   \n",
       "8                                  Rarr Technologies           10-16 Yrs   \n",
       "9                                  Rarr Technologies            6-12 Yrs   \n",
       "\n",
       "                                        job_location  \n",
       "0                     Hyderabad, Gurugram, Bengaluru  \n",
       "1                                           Gurugram  \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...  \n",
       "3         Mumbai, Pune, Chennai, Gurugram, Bengaluru  \n",
       "4                  Delhi / NCR, Hyderabad, Bengaluru  \n",
       "5                                           Gurugram  \n",
       "6                Hybrid - Noida, Gurugram, Bengaluru  \n",
       "7                       Hybrid - Gurugram, Bengaluru  \n",
       "8                                          Faridabad  \n",
       "9                                          Faridabad  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'job_title':job_title,'company_name':company_name,'experience_required':experience_required,'job_location':job_location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32758b6",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the\n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2454c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tarun\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aedc630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b43da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9317fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the shine.com website\n",
    "driver.get('https://www.shine.com/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f7cc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "\n",
    "designation= driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09495f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_loc=driver.find_element(By.XPATH,'//*[@id=\"id_loc\"]')\n",
    "search_field_loc.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdf0bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search bar button\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46881cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b8f6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//*[@id=\"1\"]/div[*]/div[1]/div[1]/strong/p/a')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//*[@id=\"1\"]/div[*]/div[1]/div[1]/div[3]/div[1]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,' //*[@id=\"1\"]/div[*]/div[1]/div[1]/div[2]/span')\n",
    "for i in company_tags[0:10]:             \n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//*[@id=\"1\"]/div[*]/div[1]/div[1]/div[3]/div[2]/div[1]')\n",
    "for i in experience_tags[0:10]:               \n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4445a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(experience_required),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be3b40f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist In SINGAPORE</td>\n",
       "      <td>adal immigrations llp</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>spento papers (india) llp</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>the christopher's consulting and re...</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "      <td>Bangalore\\n+2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>eliterecruitments hiring for global...</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Analytics</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>aryan technology</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sql data analysis</td>\n",
       "      <td>ikaya solutions private limited</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Catalog with Data Goverance</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "      <td>6 to 11 Yrs</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          job_title                            company_name  \\\n",
       "0       Data Scientist In SINGAPORE                   adal immigrations llp   \n",
       "1                    Data Scientist                           techno endura   \n",
       "2               Lead Data Scientist               spento papers (india) llp   \n",
       "3                    Data Scientist                  future solution centre   \n",
       "4                    Data Scientist  the christopher's consulting and re...   \n",
       "5                    Data Scientist  eliterecruitments hiring for global...   \n",
       "6            Data Science Analytics  mackenzie modern it solutions priva...   \n",
       "7                      Data Analyst                        aryan technology   \n",
       "8                 sql data analysis         ikaya solutions private limited   \n",
       "9  Data Catalog with Data Goverance                     ltimindtree limited   \n",
       "\n",
       "  experience_required   job_location  \n",
       "0          3 to 8 Yrs  Bangalore\\n+1  \n",
       "1          0 to 2 Yrs  Bangalore\\n+6  \n",
       "2        12 to 22 Yrs  Bangalore\\n+8  \n",
       "3          2 to 7 Yrs  Bangalore\\n+9  \n",
       "4          0 to 2 Yrs  Bangalore\\n+2  \n",
       "5          4 to 8 Yrs      Bangalore  \n",
       "6          5 to 8 Yrs  Bangalore\\n+7  \n",
       "7          0 to 4 Yrs  Bangalore\\n+4  \n",
       "8          3 to 6 Yrs  Bangalore\\n+1  \n",
       "9         6 to 11 Yrs  Bangalore\\n+8  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'job_title':job_title,'company_name':company_name,'experience_required':experience_required,'job_location':job_location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527dd78b",
   "metadata": {},
   "source": [
    "# Q3:Scrape 100 reviews data from flipkart.com for iphone11 phone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "975ef11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tarun\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "37ec3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "ba69f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9585233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the flipkart.com website\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "954ba01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the Product and click search button \n",
    "\n",
    "search_product = driver.find_element(By.XPATH,'/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "a28dcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists\n",
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "86073b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Ratings from the given page\n",
    "rating_elements = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[*]/div/div/div/div[1]/div')\n",
    "for element in rating_elements:\n",
    "    ratings.append(element.text)\n",
    "\n",
    "# Scraping Review Summaries from the given page\n",
    "review_elements = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[*]/div/div/div/div[1]/p')\n",
    "for element in review_elements:\n",
    "    review_summaries.append(element.text)\n",
    "\n",
    "# Scraping Full Reviews from the given page\n",
    "full_review_elements = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[*]/div/div/div/div[2]/div/div/div')\n",
    "for element in full_review_elements:\n",
    "    full_reviews.append(element.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "35d4452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Print the lengths of each list\n",
    "print(len(ratings), len(review_summaries), len(full_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "440a875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rating, Review_summary, Full_review]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Rating': ratings,\n",
    "    'Review_summary': review_summaries,\n",
    "    'Full_review': full_reviews\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532abf9d",
   "metadata": {},
   "source": [
    "# Q4:Scrape data forfirst 100 sneakers you find whenyouvisitflipkart.com and search for “sneakers” in the search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "414d6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tarun\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tarun\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "353b86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "25e8a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0025843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Naukri.com website\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3bea7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the Product and click search button \n",
    "\n",
    "search_product = driver.find_element(By.XPATH,'/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_product.send_keys('sneakers')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aaa00258",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.XPATH,\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "af423f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4861b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = driver.find_elements(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div[*]/div/a/div[1]/div/div')\n",
    "for i in brand[0:100]:\n",
    "    brand_tag=i.text\n",
    "    Brand.append(brand_tag)\n",
    "    \n",
    "product_description = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[*]/div/div/div[2]')\n",
    "for i in product_description[0:100]:\n",
    "    product_description_tag=i.text\n",
    "    Product_Description.append(product_description_tag)\n",
    "    \n",
    "price = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[*]/div/div/a[2]/div/div[1]')\n",
    "for i in price[0:100]:\n",
    "    price_tag=i.text\n",
    "    Price.append(price_tag)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6da33d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c44eb8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Des</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Product_Des, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand':brand,'Product_Des':product_des,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76dad8a",
   "metadata": {},
   "source": [
    "# Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU\n",
    "Type filter to “Intel Core i7” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "099f3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b7269adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Amazon.com website\n",
    "driver.get('https://www.amazon.in/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "641c0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item = driver.find_element(By.XPATH,'//*[@id=\"twotabsearchtextbox\"]')\n",
    "search_item.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e2815dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search_button = driver.find_element(By.XPATH,'//*[@id=\"nav-search-submit-button\"]')\n",
    "click_search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "01a17726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select intel core 7 filter\n",
    "\n",
    "intel_core7 = driver.find_element(By.XPATH,'//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span')\n",
    "intel_core7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "349d7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Ratings = []\n",
    "Price = []\n",
    "\n",
    "title = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[*]/div/div/span/div/div/div/div[2]/div/div/div[1]/h2')\n",
    "rating = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[*]/div/div/span/div/div/div/div[2]/div/div/div[2]/div[1]/span[1]/span/a/i[1]')\n",
    "price = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[*]/div/div/span/div/div/div/div[2]/div/div/div[3]/div[1]/div/div[1]/div[2]/div[1]/a/span/span[2]/span[2]')\n",
    "\n",
    "for i in title:Title.append(i.text)\n",
    "for i in rating:Ratings.append(i.text)    \n",
    "for i in price:Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a037690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4f3dedd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Ratings, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':title,'Ratings':rating,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c33a45",
   "metadata": {},
   "source": [
    "# Q6: Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "e18712a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6fc011fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the azquotes.com website\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "7ecbc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search_button = driver.find_element(By.XPATH,'//*[@id=\"menu\"]/div/div[3]/ul/li[5]/a')\n",
    "click_search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2b56dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote = []\n",
    "Author = []\n",
    "Type_of_quotes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "98be2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "quotes_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[*]/div/p/a[2]')\n",
    "quotes = [element.text for element in quotes_elements[:1000]]\n",
    "\n",
    "# Scraping Authors from the given page\n",
    "authors_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[*]/div/div[1]/a')\n",
    "authors = [element.text for element in authors_elements[:1000]]\n",
    "\n",
    "# Scraping Types of Quotes from the given page\n",
    "types_of_quotes_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[*]/div/div[2]/div[1]')\n",
    "types_of_quotes = [element.text for element in types_of_quotes_elements[:1000]]\n",
    "\n",
    "# Example output (optional)\n",
    "for i in range(len(quotes)):\n",
    "    print(f\"Quote: {quotes[i]}, Author: {authors[i]}, Type: {types_of_quotes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1c66afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Print the lengths of each list\n",
    "print(len(quotes), len(authors), len(types_of_quotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "9321861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [quote, author, type_of_quotes]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'quotes', 'authors', and 'types_of_quotes' are already defined and populated\n",
    "df = pd.DataFrame({\n",
    "    'quote': quotes,\n",
    "    'author': authors,\n",
    "    'type_of_quotes': types_of_quotes\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b498b6e",
   "metadata": {},
   "source": [
    "# Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name,\n",
    "\n",
    "Born-Dead, Term of office, Remarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "e079180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "24079764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "84b18bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JagranJosh.com website:\n",
    "driver.get('https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "4cf172d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the GK Option:\n",
    "gk_option = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/header/nav/div/div/div[3]/ul/li[4]/small/a')\n",
    "gk_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "46495f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"List of all Prime Ministers of India\":\n",
    "pm_option = driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div[8]/section[5]/div[2]/ul/li[3]/article/h3')\n",
    "pm_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "6fba32ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"itemdiv\"]/div[4]/div[9]/div\"}\n  (Session info: chrome=128.0.6613.138); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B6CD9412+29090]\n\t(No symbol) [0x00007FF6B6C4E239]\n\t(No symbol) [0x00007FF6B6B0B1DA]\n\t(No symbol) [0x00007FF6B6B5EFE7]\n\t(No symbol) [0x00007FF6B6B5F23C]\n\t(No symbol) [0x00007FF6B6BA97C7]\n\t(No symbol) [0x00007FF6B6B8672F]\n\t(No symbol) [0x00007FF6B6BA65A2]\n\t(No symbol) [0x00007FF6B6B86493]\n\t(No symbol) [0x00007FF6B6B509D1]\n\t(No symbol) [0x00007FF6B6B51B31]\n\tGetHandleVerifier [0x00007FF6B6FF871D+3302573]\n\tGetHandleVerifier [0x00007FF6B7044243+3612627]\n\tGetHandleVerifier [0x00007FF6B703A417+3572135]\n\tGetHandleVerifier [0x00007FF6B6D95EB6+801862]\n\t(No symbol) [0x00007FF6B6C5945F]\n\t(No symbol) [0x00007FF6B6C54FB4]\n\t(No symbol) [0x00007FF6B6C55140]\n\t(No symbol) [0x00007FF6B6C4461F]\n\tBaseThreadInitThunk [0x00007FF8FCE07374+20]\n\tRtlUserThreadStart [0x00007FF8FD51CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[491], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Locate the table\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m table \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitemdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[4]/div[9]/div\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust the XPath if necessary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:748\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    745\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    746\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"itemdiv\"]/div[4]/div[9]/div\"}\n  (Session info: chrome=128.0.6613.138); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6B6CD9412+29090]\n\t(No symbol) [0x00007FF6B6C4E239]\n\t(No symbol) [0x00007FF6B6B0B1DA]\n\t(No symbol) [0x00007FF6B6B5EFE7]\n\t(No symbol) [0x00007FF6B6B5F23C]\n\t(No symbol) [0x00007FF6B6BA97C7]\n\t(No symbol) [0x00007FF6B6B8672F]\n\t(No symbol) [0x00007FF6B6BA65A2]\n\t(No symbol) [0x00007FF6B6B86493]\n\t(No symbol) [0x00007FF6B6B509D1]\n\t(No symbol) [0x00007FF6B6B51B31]\n\tGetHandleVerifier [0x00007FF6B6FF871D+3302573]\n\tGetHandleVerifier [0x00007FF6B7044243+3612627]\n\tGetHandleVerifier [0x00007FF6B703A417+3572135]\n\tGetHandleVerifier [0x00007FF6B6D95EB6+801862]\n\t(No symbol) [0x00007FF6B6C5945F]\n\t(No symbol) [0x00007FF6B6C54FB4]\n\t(No symbol) [0x00007FF6B6C55140]\n\t(No symbol) [0x00007FF6B6C4461F]\n\tBaseThreadInitThunk [0x00007FF8FCE07374+20]\n\tRtlUserThreadStart [0x00007FF8FD51CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# Locate the table\n",
    "data = []\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"itemdiv\"]/div[4]/div[9]/div')  # Adjust the XPath if necessary\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cols) == 4:  # Ensure there are four columns\n",
    "        name = cols[0].text\n",
    "        born_dead = cols[1].text\n",
    "        term_of_office = cols[2].text\n",
    "        remarks = cols[3].text\n",
    "        data.append([name, born_dead, term_of_office, remarks])\n",
    "\n",
    "    driver.quit()\n",
    "    return data\n",
    "\n",
    "def display_data(data):\n",
    "    for entry in data:\n",
    "        print(entry)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    table_data = scrape_table()\n",
    "    display_data(table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Name', 'Born-Dead', 'Term of Office', 'Remarks'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc7af4",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to display list of 50 Most expensive cars in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "c2f04096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "dd4a3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "b8a274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the website:\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item = driver.find_element(By.XPATH, '//*[@id=\"page_index_index_index\"]/div[2]/div/div/div[3]/div')\n",
    "search_item.send_keys(\"50 most expensive cars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ebba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search_button = driver.find_element(By.XPATH,'//*[@id=\"page_index_articles_search\"]/div[6]/form/input[2]')\n",
    "click_search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "58f21703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the data and create a dataframe\n",
    "car_names = driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[2]/h3[*]')\n",
    "car_prices = driver.find_elements(By.XPATH, '//*[@id=\"article_box\"]/div[1]/div[2]/div[2]/p[*]/strong')\n",
    "\n",
    "data = []\n",
    "for name, price in zip(car_names, car_prices):    \n",
    "    data.append([name.text, price.text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "cacd6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Car Name                        Price\n",
      "0                           McLaren Senna GTR                 $1.7 Million\n",
      "1                                 Czinger 21C          Price: $1.7 Million\n",
      "2                               Ferrari Monza          Price: $1.7 Million\n",
      "3                          Gordon Murray T.33          Price: $1.7 Million\n",
      "4                           Koenigsegg Gemera          Price: $1.7 Million\n",
      "5                          Hennessey Venom F5          Price: $1.8 Million\n",
      "6                             Bentley Bacalar          Price: $1.9 Million\n",
      "7               Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
      "8                      Bentley Mulliner Batur          Price: $2.0 Million\n",
      "9                                 SSC Tuatara          Price: $2.0 Million\n",
      "10                                Lotus Evija          Price: $2.1 Million\n",
      "11                        Aston Martin Vulcan          Price: $2.3 Million\n",
      "12                                 Delage D12          Price: $2.3 Million\n",
      "13                        Ferrari Daytona SP3          Price: $2.3 Million\n",
      "14                          McLaren Speedtail          Price: $2.3 Million\n",
      "15                               Rimac Nevera          Price: $2.4 Million\n",
      "16                              Pagani Utopia          Price: $2.5 Million\n",
      "17                       Pininfarina Battista          Price: $2.5 Million\n",
      "18                         Gordon Murray T.50          Price: $2.6 Million\n",
      "19                       Lamborghini Countach          Price: $2.6 Million\n",
      "20              Hennessey Venom F5 Revolution                 $2.7 Million\n",
      "21                   Mercedes-AMG Project One          Price: $2.7 Million\n",
      "22                               Zenvo Aurora          Price: $2.8 Million\n",
      "23                        Aston Martin Victor          Price: $3.0 Million\n",
      "24                Hennessey Venom F5 Roadster                 $3.0 Million\n",
      "25                           Koenigsegg Jesko          Price: $3.0 Million\n",
      "26                                 Aspark Owl                 $3.1 Million\n",
      "27                      Aston Martin Valkyrie          Price: $3.2 Million\n",
      "28                  W Motors Lykan Hypersport          Price: $3.4 Million\n",
      "29                              McLaren Solus                 $3.5 Million\n",
      "30                        Pagani Huayra Evo R          $3.5 Million (est.)\n",
      "31                           Lamborghini Sian          Price: $3.6 million\n",
      "32                           Koenigsegg CC850          Price: $3.7 Million\n",
      "33            Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
      "34  Gordon Murray Automotive T.50s Niki Lauda                 $3.9 Million\n",
      "35                  Pagani Huayra Roadster BC                 $4.0 Million\n",
      "36                         Lamborghini Veneno          Price: $4.5 Million\n",
      "37                             Bugatti Bolide          Price: $4.7 Million\n",
      "38                  Pininfarina B95 Speedster          Price: $4.8 Million\n",
      "39                            Bugatti Mistral          Price: $5.0 Million\n",
      "40                               Bugatti Divo          Price: $5.8 Million\n",
      "41                        Pagani Huayra Imola                 $6.0 Million\n",
      "42                           Pagani Codalunga          Price: $7.4 Million\n",
      "43                   Mercedes-Maybach Exelero          Price: $8.0 Million\n",
      "44                         Bugatti Centodieci          Price: $9.0 Million\n",
      "45                    Bugatti Chiron Profilée         Price: $10.8 Million\n",
      "46                       Rolls-Royce Sweptail         Price: $12.8 Million\n",
      "47                   Bugatti La Voiture Noire         Price: $13.4 Million\n",
      "48                      Rolls-Royce Boat Tail  Price: $28.0 Million (est.)\n",
      "49         Rolls-Royce La Rose Noire Droptail    Price: $30 Million (est.)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['Car Name', 'Price'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ccb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
